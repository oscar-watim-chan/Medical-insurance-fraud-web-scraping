{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geograpy\n",
    "import pandas\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if hyperlink exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib\n",
    "\n",
    "def test_hyperlink(link):\n",
    "    link = link.encode('ascii', 'ignore').decode('ascii')\n",
    "\n",
    "    if link[0:4] == \"http\":\n",
    "        try:\n",
    "            request=urllib.request.urlopen(link)\n",
    "            if request.code == 200:    #Website exists\n",
    "                return 1\n",
    "            else:                             #Website does not work\n",
    "                return 0\n",
    "        except urllib.error.HTTPError as e:\n",
    "            return 0\n",
    "        except urllib.error.URLError as e:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-defined function for extracting geographical location & money involved from news description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try several versions of location extraction\n",
    "\n",
    "def simple_location_extract(desc):\n",
    "    if (desc.find('-')>0) & (desc.find('-')<18):\n",
    "        return desc.split('-')[0]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_extract(desc):\n",
    "    state_list = [\"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"California\", \"Colorado\", \"Connecticut\", \"Delaware\", \n",
    "                  \"Florida\", \"Georgia\", \"Hawaii\",  \"Idaho\",  \"Illinois\",  \"Indiana\",  \"Iowa\",\n",
    "                  \"Kansas\",  \"Kentucky\",  \"Louisiana\",  \"Maine\",  \"Maryland\",  \"Massachusetts\",\n",
    "                  \"Michigan\",  \"Minnesota\",  \"Mississippi\",  \"Missouri\",  \"Montana\", \"Nebraska\", \"Nevada\",\n",
    "                  \"New Hampshire\",  \"New Jersey\",  \"New Mexico\", \"New York\", \"North Carolina\", \"North Dakota\",\n",
    "                  \"Ohio\",  \"Oklahoma\",  \"Oregon\",  \"Pennsylvania\",  \"Rhode Island\",  \"South Carolina\",  \"South Dakota\",\n",
    "                  \"Tennessee\",  \"Texas\",  \"Utah\",  \"Vermont\",  \"Virginia\", \"Washington\",  \"West Virginia\"\n",
    "                  \"Wisconsin\",  \"Wyoming\", \"Puerto Rico\"]\n",
    "    return_state = ''\n",
    "    \n",
    "    for state in state_list:\n",
    "        if (desc.find(state)>-1) & (return_state==''):\n",
    "            return_state = state\n",
    "    \n",
    "    return return_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try location scraper\n",
    "\n",
    "def geo_cities_extract(desc):\n",
    "     return geograpy.get_place_context(text = desc).cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_regions_extract(desc):\n",
    "     return geograpy.get_place_context(text = desc).regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try place scraper\n",
    "\n",
    "def geo_places_extract(desc):\n",
    "     return geograpy.get_place_context(text = desc).places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract money involved or punishment amount\n",
    "\n",
    "def money_involved(desc):\n",
    "    regex = r\"(?:[\\£\\$\\€]{1}[,\\d]+.?\\d*)\"  \n",
    "    list_of_units = ['thousand', 'million', 'billion', 'Thousand', 'Million', 'Billion', 'M']    \n",
    "    \n",
    "    matches = re.finditer(regex, desc)\n",
    "    \n",
    "    money_array = []\n",
    "    for x in matches:\n",
    "        startpt = x.start()\n",
    "        endpt = x.end()\n",
    "        money = str(x.group())\n",
    "        \n",
    "        money = re.sub('[^0-9a-zA-Z\\.]+', '', money)\n",
    "        \n",
    "        # Add back quantifying units such as 'thousand'/'million/ etc'\n",
    "        for unit in list_of_units:\n",
    "            if len(desc[endpt:]) >= len(unit):\n",
    "                if (desc[endpt:endpt+len(unit)] == unit) or (desc[endpt+1:endpt+len(unit)+1] == unit) :\n",
    "                    if desc[endpt+1:endpt+len(unit)+1] == unit:\n",
    "                        money = money + ' '+unit\n",
    "                    else:\n",
    "                        money = money + unit\n",
    "        \n",
    "        money = money.replace('MillionM', 'Million')\n",
    "        money = money.replace('Million M', 'Million')\n",
    "        money_array.append(money)\n",
    "    \n",
    "    if len(money_array)==1:        # Only one element - to be stored directly\n",
    "        return money_array[0]\n",
    "    elif len(money_array)==0:      # None exist\n",
    "        return None\n",
    "    else:\n",
    "        return money_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desc done\n",
      "Title done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CWT\\Anaconda\\lib\\site-packages\\xlsxwriter\\worksheet.py:830: UserWarning: Ignoring URL 'https://www.justice.gov/opa/pr/national-medicare-fraud-takedown-results-charges-against-243-individuals-approximately-712,%20/fraud/enforcement/files/Fact_Sheet_Takedown_6_8_2015.pdf,%20https://www.justice.gov/opa/documents-and-resources-june-2015-medicare-fraud-strike-force-press-conference,%20/newsroom/video/index.asp' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n",
      "C:\\Users\\CWT\\Anaconda\\lib\\site-packages\\xlsxwriter\\worksheet.py:830: UserWarning: Ignoring URL 'https://www.justice.gov/usao/mie/news/2011/2011_7_28_gwashingtonmd.html, https://www.justice.gov/usao/fls/PressReleases/110727-03.html, https://www.justice.gov/usao/ct/Press2011/20110727.html, https://www.justice.gov/usao/txw/press_releases/2011/Medicare_Fraud_scheme_SA_ind.pdf, https://www.justice.gov/usao/md/Public-Affairs/press_releases/press08/SalisburyCardiologistConvictedofImplantingUnnecessaryCardiacStents.html, https://www.justice.gov/opa/pr/2011/July/11-crm-970.html, https://www.justice.gov/opa/pr/2011/July/11-civ-966.html, https://www.justice.gov/usao/mn/press/jul031.pdf, https://www.justice.gov/usao/cac/pressroom/pr2011/104.html, https://www.justice.gov/opa/pr/2011/July/11-crm-952.html, https://www.justice.gov/usao/ma/news/2011/July/McGeePleaPR.html, https://www.justice.gov/usao/iln/pr/chicago/2011/pr0720_02.pdf, https://www.justice.gov/usao/co/press_releases/2011/July2011/7_20_11.html, https://www.justice.gov/usao/lam/press/press1107.html, https://www.justice.gov/usao/tne/news/2011/July/071511%20Foster%20Sentencing%20Health%20Care%20Fraud%20html.html, https://www.justice.gov/usao/ilc/press/2011/07July/14Gupta.html, https://www.justice.gov/opa/pr/2011/July/11-crm-920.html , https://www.justice.gov/opa/pr/2011/July/11-crm-914.html, https://www.justice.gov/opa/pr/2011/July/11-crm-909.html, https://www.justice.gov/usao/tnm/pressReleases/2011/7-13-11.html, https://www.justice.gov/usao/waw/press/2011/jul/chan.html, https://www.justice.gov/opa/pr/2011/July/11-crm-907.html, https://www.justice.gov/usao/nj/Press/files/Lynch,%20Patrick%20Plea%20PR.html,  https://www.justice.gov/usao/nys/pressreleases/July11/kazarianarmenpleapr.pdf, https://www.justice.gov/usao/ct/Press2011/20110708.html, https://www.justice.gov/opa/pr/2011/July/11-crm-896.html, https://www.fbi.gov/atlanta/press-releases/2011/atlanta-radiologist-guilty-of-fraudulently-passing-off-diagnoses-prepared-by-non-physician-employees, https://www.justice.gov/usao/pam/news/2011/Salko_07_06_2011.htm, https://www.justice.gov/opa/pr/2011/July/11-crm-886.html, https://www.justice.gov/usao/md/Public-Affairs/press_releases/press08/GambrillsPodiatristPleadsGuiltytoFraudulentlyBillingMedicareover1.1Million.html' with link or location/anchor > 255 characters since it exceeds Excel's limit for URLS\n",
      "  force_unicode(url))\n"
     ]
    }
   ],
   "source": [
    "filename = 'OIG_HHS_Scrape_allyears_intermediate.csv'\n",
    "df = pandas.read_csv('Raw/'+filename) \n",
    "\n",
    "#From description\n",
    "df['Description_Location'] = df['description'].apply(lambda x:  simple_location_extract(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "df['Description_State'] = df['description'].apply(lambda x:  state_extract(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "df['Description_Money_involved'] = df['description'].apply(lambda x:  money_involved(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "print('Desc done')\n",
    "\n",
    "#From title\n",
    "df['Heading_Location'] = df['heading'].apply(lambda x:  simple_location_extract(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "df['Heading_State'] = df['heading'].apply(lambda x:  state_extract(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "df['Heading_Money_involved'] = df['heading'].apply(lambda x:  money_involved(x) if  (type(x)==str) &  (len(str(x))>0) else x)\n",
    "print('Title done')\n",
    "\n",
    "#Test hyperlink\n",
    "df['hyperlink_valid'] = df['hyperlink'].apply(lambda x:  test_hyperlink(x) if  (type(x)==str) &  (len(str(x))>0) else -999)\n",
    "\n",
    "#df.to_excel('Cleaned/' + filename +'_v2.xlsx', sheet_name='Sheet1')\n",
    "df.to_excel('Cleaned/OIG_HHS_Scrape_allyears.xlsx', sheet_name='Sheet1', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-direct completed dataset to csv instead \n",
    "df.to_csv('Cleaned/OIG_HHS_Scrape_allyears.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
